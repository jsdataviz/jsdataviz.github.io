{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f1d36e0-1be9-48e2-b01d-c483c7a287b8",
   "metadata": {},
   "source": [
    "## RideLondon Data scrape\n",
    "This notebook scrapes race times, including individual detailed rider times from the [Ride London results web portal](https://results.ridelondon.co.uk/2024/). It provides a file for each race length and year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2230aa30-0380-4cfe-8e6a-0e52dbe3fdcf",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfdcf185-3984-447c-836e-676257675ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "import re\n",
    "import math\n",
    "import os\n",
    "from datetime import datetime, time, timedelta\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d612a57-2f6b-480a-8e80-327bd57df4c1",
   "metadata": {},
   "source": [
    "## Initialise race information.\n",
    "Set the events you wish to retrieve data for, defaulting to all race types and sexes for 2024 & 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0093c8d-a140-4cd2-8225-929885090832",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2024, 2023]\n",
    "registered_sexes = ['M', 'W']\n",
    "events = [\"I\", 'I60', 'I30']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9912ef2a-438c-43d8-b116-26fbc3e169b7",
   "metadata": {},
   "source": [
    "## Initialise scraper functions\n",
    "Initialise functions that we be used over multiple pages during the scrape.\n",
    "\n",
    "### `get_rider_urls`\n",
    "A function that scans a [search result page](https://results.ridelondon.co.uk/2024/?pid=list) and returns the URL to each rider's detailed results page for all riders on the page.\n",
    "\n",
    "### `get_ride_info`\n",
    "A function that scans a rider's [detailed ride information page](https://results.ridelondon.co.uk/2024/?content=detail&fpid=search&pid=search&idp=9TGCPGHIDAF54&lang=EN_CAP&event=I&search%5Bname%5D=Smith&search%5Bfirstname%5D=Joseph&search_event=I), and parses: \n",
    "\n",
    "- The \"Participant\" table, which contains the charity info. \n",
    "- The \"Status\" table, containing the rider's finish state.\n",
    "- The \"Timing Points\" table, containing the riders detailed times per checkpoint.\n",
    "\n",
    "If the rider's tables do not match the standard ride page schema, they are skipped.\n",
    "\n",
    "### `get_all_pages`\n",
    "A function that uses `get_rider_urls` and `get_ride_info` to loop through all search pages and detailed ride pages and concatinates all race data into one file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5ae36e-56cb-44e9-8af7-7a118b0e1301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rider_urls(soup):\n",
    "    # Find all parent elements with class 'type-fullname' and extract hrefs\n",
    "    hrefs = []\n",
    "    for element in soup.find_all(class_='type-fullname'):\n",
    "        # Find all anchor tags inside the parent element\n",
    "        a_tag = element.find('a')\n",
    "        if a_tag and a_tag.has_attr('href'):\n",
    "            hrefs.append(a_tag['href'])\n",
    "\n",
    "    return hrefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "816dc845-c969-4fcc-80b0-81156469c04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ride_info(base_url, rider_url, event):\n",
    "    full_url = base_url + rider_url\n",
    "\n",
    "    session = requests.Session()\n",
    "    retry = Retry(connect=5, backoff_factor=1, status_forcelist=[502, 503, 504])\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    \n",
    "    try:\n",
    "        response = session.get(full_url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to fetch data for {rider_url}, Status code: {response.status_code}\")\n",
    "            return pd.DataFrame()  # Return empty DataFrame if the request fails\n",
    "\n",
    "        # Parse the HTML content from the GET response\n",
    "        get_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Initialize a list to store the pivoted tables\n",
    "        pivoted_tables = []\n",
    "        \n",
    "        # Define the classes containing tables\n",
    "        target_classes = ['box-general', 'box-totals', 'box-state']\n",
    "        for target_class in target_classes:\n",
    "            box = get_soup.find(class_=target_class)\n",
    "            if box:\n",
    "                html_string = str(box)\n",
    "                tables = pd.read_html(StringIO(html_string))\n",
    "                for table in tables:\n",
    "                    # Ensure the table has valid rows\n",
    "                    if not table.empty:\n",
    "                        # Pivoting the DataFrame\n",
    "                        pivoted_final_frame_renamed = table.set_index(0).T.reset_index(drop=True)\n",
    "                        pivoted_final_frame_renamed.columns.name = None  # Remove column names\n",
    "                        pivoted_tables.append(pivoted_final_frame_renamed)\n",
    "        \n",
    "        # Handling the \"splits\" table\n",
    "        split_html = get_soup.find(class_='box-splits')\n",
    "        if split_html:\n",
    "            html_string = str(split_html)\n",
    "            tables = pd.read_html(StringIO(html_string))\n",
    "            if tables:\n",
    "                table = tables[0]\n",
    "\n",
    "                # Create a flattened dictionary for the new row format\n",
    "                flattened_data = {}\n",
    "\n",
    "                # Custom labels for columns\n",
    "                labels = {\n",
    "                    \"I\": ['arr25', 'dep26', 'arr53', 'dep54', 'arr73', 'dep74', 'finish'],\n",
    "                    \"I60\": ['arr25', 'dep26', 'arr32', 'dep33', 'finish'],\n",
    "                    \"I30\": ['finish']\n",
    "                }\n",
    "\n",
    "                # Extract the data based on the column labels\n",
    "                for i, label in enumerate(labels.get(event, [])):\n",
    "                    flattened_data[f'{label}_tod'] = table['Time Of Day'][i] if 'Time Of Day' in table.columns else 'N/A'\n",
    "                    flattened_data[f'{label}_time'] = table['Time'][i] if 'Time' in table.columns else 'N/A'\n",
    "                    flattened_data[f'{label}_diff'] = table['diff.'][i] if 'diff.' in table.columns else 'N/A'\n",
    "                    flattened_data[f'{label}_mph'] = table['mph'][i] if 'mph' in table.columns else 'N/A'\n",
    "\n",
    "                # Convert the flattened data dictionary back into a DataFrame with one row\n",
    "                split_final_frame_renamed = pd.DataFrame([flattened_data])\n",
    "                pivoted_tables.append(split_final_frame_renamed)\n",
    "\n",
    "        # Concatenate all the tables if there are any\n",
    "        if pivoted_tables:\n",
    "            concat_frame = pd.concat(pivoted_tables, axis=1, ignore_index=True)\n",
    "            return concat_frame\n",
    "        else:\n",
    "            print(f\"No data found for {rider_url}\")\n",
    "            return pd.DataFrame()  # Return an empty DataFrame if no tables were found\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed for {full_url}: {e}. Retrying now\")\n",
    "        i -= 1\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if the request fails\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError for {rider_url}: {e}\")\n",
    "        return pd.DataFrame()  # Skip this rider and return an empty DataFrame\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {rider_url}: {e}\")\n",
    "        return pd.DataFrame()  # Skip this rider on unexpected errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "968656a0-0a1e-4ddf-b1c2-7d75d2f00ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_pages(year, event, sex):\n",
    "\n",
    "    base_url = f'https://results.ridelondon.co.uk/{year}/'\n",
    "\n",
    "    session = requests.Session()\n",
    "    retry = Retry(connect=5, backoff_factor=1, status_forcelist=[502, 503, 504])\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    \n",
    "    query_params = {\n",
    "        \"page\": \"1\",\n",
    "        \"event\": event,\n",
    "        \"num_results\": \"100\",\n",
    "        \"pid\": \"list\",\n",
    "        \"pidp\": \"start\",\n",
    "        \"search[sex]\": sex,\n",
    "    }\n",
    "\n",
    "    response = session.get(base_url, params=query_params, timeout=10)\n",
    "    \n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    match = re.search(r'(\\d+) Times', response.text)\n",
    "    number_of_times = int(match.group(1))\n",
    "    number_of_pages = math.ceil(number_of_times / 100)\n",
    "    step = number_of_pages // 10\n",
    "    \n",
    "    # Final DataFrame to hold the concatenated data from all pages\n",
    "    \n",
    "    for i in range(1, number_of_pages + 1):\n",
    "        try:\n",
    "            query_params[\"page\"] = i\n",
    "            response = session.get(base_url, params=query_params, timeout=10)\n",
    "            response.raise_for_status()  # Check for errors\n",
    "\n",
    "            # Parse and process page data here\n",
    "            rider_frames = []\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "\n",
    "            hrefs = get_rider_urls(soup)\n",
    "            for href in hrefs:\n",
    "                rider_frame = get_ride_info(base_url, href, query_params[\"event\"])\n",
    "                rider_frames.append(rider_frame)\n",
    "        \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request failed on page {i}: {e}. Retrying now.\")\n",
    "            i -= 1\n",
    "            continue  # Skip to the next page on failure\n",
    "    \n",
    "        final_frame_renamed = pd.concat(rider_frames)\n",
    "    \n",
    "        final_frame_renamed['sex'] = query_params['search[sex]']\n",
    "        final_frame_renamed['year'] = year\n",
    "    \n",
    "        final_frame_renamed = final_frame_renamed.rename(columns={\n",
    "            'Name': 'name',\n",
    "            'Rider number': 'rider_number',\n",
    "            'Charity': 'charity',\n",
    "            'Event': 'event',\n",
    "            'Finish': 'finish_time',\n",
    "            'Status': 'status',\n",
    "            'Last Timing Point': 'last_timing_point'\n",
    "        })\n",
    "        \n",
    "        final_frame_renamed.to_csv(f\"data/{year}_event_{query_params[\"event\"]}_{query_params[\"search[sex]\"]}_page_{query_params[\"page\"]}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6082d57-08db-484a-8fe9-78a6d791c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('./data')\n",
    "os.mkdir('./web_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3838a00-46fa-485b-b15e-20b046f9b86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_frame_renamed.to_csv(fullname)\n",
    "\n",
    "for year in years:\n",
    "    for event in events:\n",
    "        for sex in registered_sexes:\n",
    "            get_all_pages(year, event, sex)\n",
    "\n",
    "for event in events:\n",
    "    final_frame_renameds = []\n",
    "    \n",
    "    # Loop over all files in the directory\n",
    "    for filename in os.listdir(\"./data\"):\n",
    "        if filename.endswith('.csv') and (event + '_') in filename:\n",
    "            # Read the CSV file and append the DataFrame to the list\n",
    "            final_frame_renamed = pd.read_csv(\"./data/\" + filename)\n",
    "            final_frame_renameds.append(final_frame_renamed)\n",
    "\n",
    "    # If there are any files for this race type, concatenate them\n",
    "    if final_frame_renameds:\n",
    "        combined_final_frame_renamed = pd.concat(final_frame_renameds)\n",
    "        # Save the combined DataFrame to a CSV\n",
    "        combined_final_frame_renamed.to_csv(f\"./data/final_{event}_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de79c3f4-bc69-469f-a0ac-5c8d4bd416b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def random_datetime(start, end):\n",
    "    \"\"\"Generate a random datetime between two datetime objects.\"\"\"\n",
    "    delta = end - start\n",
    "    int_delta = int(delta.total_seconds())\n",
    "    random_second = random.randint(0, int_delta)\n",
    "    return start + timedelta(seconds=random_second)\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "wave1_start_dt = datetime(2024, 5, 26, 6, 0, 0)\n",
    "wave2_start_dt = datetime(2024, 5, 26, 6, 45, 0)\n",
    "wave3_start_dt = datetime(2024, 5, 26, 7, 35, 0)\n",
    "wave4_start_dt = datetime(2024, 5, 26, 8, 15, 0)\n",
    "final_sim_start_dt = datetime(2024, 5, 26, 9, 0, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f8d7eee-7ee3-438c-a2a2-eed1f11c7065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h8/dz6krpcx2yb_86vz5sx_qczw0000gp/T/ipykernel_6007/978022514.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_frame_renamed['tod_25'] = pd.to_datetime(final_frame_renamed['tod_25'], format='%H:%M:%S', errors='coerce')\n",
      "/var/folders/h8/dz6krpcx2yb_86vz5sx_qczw0000gp/T/ipykernel_6007/978022514.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_frame_renamed['ride_time_25_delta'] = pd.to_timedelta(final_frame_renamed['ride_time_25'], errors='coerce')\n",
      "/var/folders/h8/dz6krpcx2yb_86vz5sx_qczw0000gp/T/ipykernel_6007/978022514.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_frame_renamed['start_tod'] = final_frame_renamed['tod_25'] - final_frame_renamed['ride_time_25_delta']\n",
      "/var/folders/h8/dz6krpcx2yb_86vz5sx_qczw0000gp/T/ipykernel_6007/978022514.py:65: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[NaT NaT NaT ... datetime.time(6, 7, 47) datetime.time(6, 1, 50)\n",
      " datetime.time(6, 1, 50)]' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  final_frame_renamed.loc[:, col] = pd.to_datetime(final_frame_renamed[col], format='%H:%M:%S', errors='coerce').dt.time\n"
     ]
    }
   ],
   "source": [
    "race_100_frame = pd.read_csv('./data/final_I_data.csv', low_memory=False)\n",
    "column_names = [\n",
    "    \"index\",\n",
    "    \"rider_name\",\n",
    "    \"rider_no\",\n",
    "    \"charity_name\",\n",
    "    \"event\",\n",
    "    \"final_time\",\n",
    "    \"final_status\",\n",
    "    \"final_checkout\",\n",
    "    \"tod_25\",\n",
    "    \"ride_time_25\",\n",
    "    \"diff_25\",\n",
    "    \"mph_25\",\n",
    "    \"tod_26\",\n",
    "    \"ride_time_26\",\n",
    "    \"diff_256\",\n",
    "    \"mph_26\",\n",
    "    \"tod_53\",\n",
    "    \"ride_time_53\",\n",
    "    \"diff_53\",\n",
    "    \"mph_53\",\n",
    "    \"tod_54\",\n",
    "    \"ride_time_54\",\n",
    "    \"diff_54\",\n",
    "    \"mph_54\",\n",
    "    \"tod_73\",\n",
    "    \"ride_time_73\",\n",
    "    \"diff_73\",\n",
    "    \"mph_73\",\n",
    "    \"tod_74\",\n",
    "    \"ride_time_74\",\n",
    "    \"diff_74\",\n",
    "    \"mph_74\",\n",
    "    \"tod_finish\",\n",
    "    \"ride_time_finish\",\n",
    "    \"diff_finish\",\n",
    "    \"mph_finish\",\n",
    "    \"sex\",\n",
    "    \"year\"\n",
    "]\n",
    "final_frame_renamed = race_100_frame\n",
    "\n",
    "final_frame_renamed.columns = column_names\n",
    "final_frame_renamed.sort_values(by=['year', 'final_time'], inplace=True)\n",
    "final_frame_renamed[\"rider_pos\"] = final_frame_renamed.groupby('year')['final_time'].rank(method='max')\n",
    "final_frame_renamed = final_frame_renamed[final_frame_renamed['rider_no'] != 126413]\n",
    "\n",
    "# Define the target date\n",
    "race_date = datetime(2024, 5, 26)\n",
    "\n",
    "# Convert 'tod_25' to datetime format, invalid entries will become NaT\n",
    "final_frame_renamed['tod_25'] = pd.to_datetime(final_frame_renamed['tod_25'], format='%H:%M:%S', errors='coerce')\n",
    "\n",
    "# Convert 'ride_time_25' to timedelta format\n",
    "final_frame_renamed['ride_time_25_delta'] = pd.to_timedelta(final_frame_renamed['ride_time_25'], errors='coerce')\n",
    "\n",
    "# Subtract ride_time_25 from tod_25, NaT entries will remain NaT\n",
    "final_frame_renamed['start_tod'] = final_frame_renamed['tod_25'] - final_frame_renamed['ride_time_25_delta']\n",
    "\n",
    "# Loop through all columns in final_frame_renamed that contain '_tod'\n",
    "for col in final_frame_renamed.columns:\n",
    "    if '_tod' in col:\n",
    "        # Convert to datetime, invalid entries will become NaT\n",
    "        final_frame_renamed.loc[:, col] = pd.to_datetime(final_frame_renamed[col], format='%H:%M:%S', errors='coerce').dt.time\n",
    "        \n",
    "        # Set the date to 26 May 2024 for valid entries\n",
    "        final_frame_renamed.loc[:, col] = final_frame_renamed[col].apply(lambda t: datetime.combine(race_date, t) if pd.notnull(t) else pd.NaT)\n",
    "\n",
    "# Function to convert time in HH:MM:SS to decimal hours, with error handling\n",
    "def time_to_decimal_hours(time_str):\n",
    "    try:\n",
    "        # Ensure the time string is valid and not empty\n",
    "        if pd.isnull(time_str) or time_str.strip() == '' or time_str == \"–\":\n",
    "            return None  # Return None for invalid entries\n",
    "        # Split the time string and convert to hours, minutes, and seconds\n",
    "        h, m, s = map(int, time_str.split(':'))\n",
    "        total_seconds = h * 3600 + m * 60 + s\n",
    "        return total_seconds / 3600  # Convert to hours\n",
    "    except Exception:\n",
    "        return None  # Return None if there's any issue during conversion\n",
    "\n",
    "# Ensure that final_frame_renamed is a copy, not a view\n",
    "final_frame_renamed = final_frame_renamed.copy()\n",
    "\n",
    "# Loop through all columns in final_frame_renamed that contain 'time'\n",
    "for col in final_frame_renamed.columns:\n",
    "    if 'time' in col:\n",
    "        # Apply the conversion function using .loc to avoid the SettingWithCopyWarning\n",
    "        final_frame_renamed.loc[:, col + '_decimal'] = final_frame_renamed[col].apply(time_to_decimal_hours)\n",
    "\n",
    "final_frame_renamed['start_tod_timestring'] = pd.to_datetime(final_frame_renamed['start_tod'])\n",
    "\n",
    "# mark riders as early and late starters if they didn't begin in their desiginated waves\n",
    "final_frame_renamed['is_early_starter'] = (\n",
    "    ((final_frame_renamed['rider_no'] >= 110000) & (final_frame_renamed['rider_no'] <= 116500) & (final_frame_renamed['start_tod_timestring'].dt.time < time(6,45,0))) |\n",
    "    ((final_frame_renamed['rider_no'] >= 116500) & (final_frame_renamed['rider_no'] <= 122500) & (final_frame_renamed['start_tod_timestring'].dt.time < time(7,35,0))) |\n",
    "    ((final_frame_renamed['rider_no'] >= 123000) & (final_frame_renamed['rider_no'] <= 129000) & (final_frame_renamed['start_tod_timestring'].dt.time < time(8,15,0)))\n",
    ")\n",
    "\n",
    "final_frame_renamed['is_late_starter'] = (\n",
    "    ((final_frame_renamed['rider_no'] >= 103700) & (final_frame_renamed['rider_no'] <= 110000) & (final_frame_renamed['start_tod_timestring'].dt.time > time(6,45,0))) |\n",
    "    ((final_frame_renamed['rider_no'] >= 110000) & (final_frame_renamed['rider_no'] <= 116500) & (final_frame_renamed['start_tod_timestring'].dt.time > time(7,35,0))) |\n",
    "    ((final_frame_renamed['rider_no'] >= 116000) & (final_frame_renamed['rider_no'] <= 122500) & (final_frame_renamed['start_tod_timestring'].dt.time > time(8,15,0)))\n",
    ")\n",
    "\n",
    "def assign_simulated_start_dt(row):\n",
    "    if ((row['is_early_starter'] or row['is_late_starter']) and \n",
    "        103700 <= row['rider_no'] <= 110000):\n",
    "        return random_datetime(wave1_start_dt, wave2_start_dt)\n",
    "    \n",
    "    elif ((row['is_early_starter'] or row['is_late_starter']) and \n",
    "          110000 < row['rider_no'] <= 116500):\n",
    "        return random_datetime(wave2_start_dt, wave3_start_dt)\n",
    "    \n",
    "    elif ((row['is_early_starter'] or row['is_late_starter']) and \n",
    "          116000 < row['rider_no'] <= 122500):\n",
    "        return random_datetime(wave3_start_dt, wave4_start_dt)\n",
    "    \n",
    "    elif ((row['is_early_starter'] or row['is_late_starter']) and \n",
    "          123000 <= row['rider_no'] <= 129000):\n",
    "        return random_datetime(wave4_start_dt, final_sim_start_dt)\n",
    "\n",
    "    else:\n",
    "        return row['start_tod']\n",
    "\n",
    "def assign_wave_number(row):\n",
    "    if (103700 <= row['rider_no'] <= 110000):\n",
    "        return 'Wave 1'\n",
    "    elif (110000 < row['rider_no'] <= 116500):\n",
    "        return 'Wave 2'\n",
    "    elif (116000 < row['rider_no'] <= 122500):\n",
    "        return 'Wave 3'\n",
    "    elif (123000 <= row['rider_no'] <= 129000):\n",
    "        return 'Wave 4'\n",
    "    else:\n",
    "        return 'VIP'\n",
    "\n",
    "# Apply the function row-wise\n",
    "final_frame_renamed['simulated_start_dt'] = final_frame_renamed.apply(assign_simulated_start_dt, axis=1)\n",
    "\n",
    "final_frame_renamed.to_csv('./web_data/parsed_I_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f71a33f-b900-4668-9913-59037f6951b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_60_frame = pd.read_csv('./data/final_I60_data.csv', low_memory=False)\n",
    "column_names = [\n",
    "    \"index\",\n",
    "    \"rider_name\",\n",
    "    \"rider_no\",\n",
    "    \"charity_name\",\n",
    "    \"event\",\n",
    "    \"final_time\",\n",
    "    \"final_status\",\n",
    "    \"final_checkout\",\n",
    "    \"tod_25\",\n",
    "    \"ride_time_25\",\n",
    "    \"diff_25\",\n",
    "    \"mph_25\",\n",
    "    \"tod_26\",\n",
    "    \"ride_time_26\",\n",
    "    \"diff_26\",\n",
    "    \"mph_26\",\n",
    "    \"tod_32\",\n",
    "    \"ride_time_32\",\n",
    "    \"diff_32\",\n",
    "    \"mph_32\",\n",
    "    \"tod_33\",\n",
    "    \"ride_time_33\",\n",
    "    \"diff_33\",\n",
    "    \"mph_33\",\n",
    "    \"tod_finish\",\n",
    "    \"ride_time_finish\",\n",
    "    \"diff_finish\",\n",
    "    \"mph_finish\",\n",
    "    \"sex\",\n",
    "    \"year\"\n",
    "]\n",
    "final_frame_renamed = race_60_frame\n",
    "\n",
    "final_frame_renamed.columns = column_names\n",
    "final_frame_renamed.sort_values(by=['year', 'final_time'], inplace=True)\n",
    "final_frame_renamed[\"rider_pos\"] = final_frame_renamed.groupby('year')['final_time'].rank(method='max')\n",
    "final_frame_renamed = final_frame_renamed[final_frame_renamed['rider_no'] != 126413]\n",
    "\n",
    "# Define the target date\n",
    "race_date = datetime(2024, 5, 26)\n",
    "\n",
    "# Convert 'tod_25' to datetime format, invalid entries will become NaT\n",
    "final_frame_renamed['tod_25'] = pd.to_datetime(final_frame_renamed['tod_25'], format='%H:%M:%S', errors='coerce')\n",
    "\n",
    "# Convert 'ride_time_25' to timedelta format\n",
    "final_frame_renamed['ride_time_25_delta'] = pd.to_timedelta(final_frame_renamed['ride_time_25'], errors='coerce')\n",
    "\n",
    "# Subtract ride_time_25 from tod_25, NaT entries will remain NaT\n",
    "final_frame_renamed['start_tod'] = final_frame_renamed['tod_25'] - final_frame_renamed['ride_time_25_delta']\n",
    "\n",
    "# Loop through all columns in final_frame_renamed that contain '_tod'\n",
    "for col in final_frame_renamed.columns:\n",
    "    if '_tod' in col:\n",
    "        # Convert to datetime, invalid entries will become NaT\n",
    "        final_frame_renamed.loc[:, col] = pd.to_datetime(final_frame_renamed[col], format='%H:%M:%S', errors='coerce').dt.time\n",
    "        \n",
    "        # Set the date to 26 May 2024 for valid entries\n",
    "        final_frame_renamed.loc[:, col] = final_frame_renamed[col].apply(lambda t: datetime.combine(race_date, t) if pd.notnull(t) else pd.NaT)\n",
    "\n",
    "# Function to convert time in HH:MM:SS to decimal hours, with error handling\n",
    "def time_to_decimal_hours(time_str):\n",
    "    try:\n",
    "        # Ensure the time string is valid and not empty\n",
    "        if pd.isnull(time_str) or time_str.strip() == '' or time_str == \"–\":\n",
    "            return None  # Return None for invalid entries\n",
    "        # Split the time string and convert to hours, minutes, and seconds\n",
    "        h, m, s = map(int, time_str.split(':'))\n",
    "        total_seconds = h * 3600 + m * 60 + s\n",
    "        return total_seconds / 3600  # Convert to hours\n",
    "    except Exception:\n",
    "        return None  # Return None if there's any issue during conversion\n",
    "\n",
    "# Ensure that final_frame_renamed is a copy, not a view\n",
    "final_frame_renamed = final_frame_renamed.copy()\n",
    "\n",
    "# Loop through all columns in final_frame_renamed that contain 'time'\n",
    "for col in final_frame_renamed.columns:\n",
    "    if 'time' in col:\n",
    "        # Apply the conversion function using .loc to avoid the SettingWithCopyWarning\n",
    "        final_frame_renamed.loc[:, col + '_decimal'] = final_frame_renamed[col].apply(time_to_decimal_hours)\n",
    "\n",
    "final_frame_renamed.to_csv('./web_data/parsed_I60_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98af8041-df58-477e-a3a4-aa89f77238ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_30_frame = pd.read_csv('./data/final_I30_data.csv', low_memory=False)\n",
    "column_names = [\n",
    "    \"index\",\n",
    "    \"rider_name\",\n",
    "    \"rider_no\",\n",
    "    \"charity_name\",\n",
    "    \"event\",\n",
    "    \"final_time\",\n",
    "    \"final_status\",\n",
    "    \"final_checkout\",\n",
    "    \"tod_finish\",\n",
    "    \"ride_time_finish\",\n",
    "    \"diff_finish\",\n",
    "    \"mph_finish\",\n",
    "    \"sex\",\n",
    "    \"year\"\n",
    "]\n",
    "final_frame_renamed = race_30_frame\n",
    "\n",
    "final_frame_renamed.columns = column_names\n",
    "final_frame_renamed.sort_values(by=['year', 'final_time'], inplace=True)\n",
    "final_frame_renamed[\"rider_pos\"] = final_frame_renamed.groupby('year')['final_time'].rank(method='max')\n",
    "final_frame_renamed = final_frame_renamed[final_frame_renamed['rider_no'] != 126413]\n",
    "\n",
    "# Define the target date\n",
    "race_date = datetime(2024, 5, 26)\n",
    "\n",
    "# Loop through all columns in final_frame_renamed that contain '_tod'\n",
    "for col in final_frame_renamed.columns:\n",
    "    if '_tod' in col:\n",
    "        # Convert to datetime, invalid entries will become NaT\n",
    "        final_frame_renamed.loc[:, col] = pd.to_datetime(final_frame_renamed[col], format='%H:%M:%S', errors='coerce').dt.time\n",
    "        \n",
    "        # Set the date to 26 May 2024 for valid entries\n",
    "        final_frame_renamed.loc[:, col] = final_frame_renamed[col].apply(lambda t: datetime.combine(race_date, t) if pd.notnull(t) else pd.NaT)\n",
    "\n",
    "# Function to convert time in HH:MM:SS to decimal hours, with error handling\n",
    "def time_to_decimal_hours(time_str):\n",
    "    try:\n",
    "        # Ensure the time string is valid and not empty\n",
    "        if pd.isnull(time_str) or time_str.strip() == '' or time_str == \"–\":\n",
    "            return None  # Return None for invalid entries\n",
    "        # Split the time string and convert to hours, minutes, and seconds\n",
    "        h, m, s = map(int, time_str.split(':'))\n",
    "        total_seconds = h * 3600 + m * 60 + s\n",
    "        return total_seconds / 3600  # Convert to hours\n",
    "    except Exception:\n",
    "        return None  # Return None if there's any issue during conversion\n",
    "\n",
    "# Ensure that final_frame_renamed is a copy, not a view\n",
    "final_frame_renamed = final_frame_renamed.copy()\n",
    "\n",
    "# Loop through all columns in final_frame_renamed that contain 'time'\n",
    "for col in final_frame_renamed.columns:\n",
    "    if 'time' in col:\n",
    "        # Apply the conversion function using .loc to avoid the SettingWithCopyWarning\n",
    "        final_frame_renamed.loc[:, col + '_decimal'] = final_frame_renamed[col].apply(time_to_decimal_hours)\n",
    "\n",
    "final_frame_renamed.to_csv('./web_data/parsed_I30_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d08736-3709-4444-83a1-15c5084a6a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
