{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a54f89-bff0-464d-b876-2702dc41859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import re\n",
    "import math\n",
    "import os\n",
    "from datetime import datetime, time, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35aae882-f6e7-4deb-90c6-fea7810f47e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_decimal_hours(time_val):\n",
    "    try:\n",
    "        if pd.isnull(time_val) or str(time_val).strip() == '' or str(time_val) == \"â€“\":\n",
    "            return None\n",
    "\n",
    "        # If it's a string, convert to datetime\n",
    "        if isinstance(time_val, str):\n",
    "            time_val = datetime.strptime(time_val.strip(), '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        # Now it's a datetime object\n",
    "        total_seconds = time_val.hour * 3600 + time_val.minute * 60 + time_val.second\n",
    "        return total_seconds / 3600\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e} with value {time_val}\")  # Helpful for debugging\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f915fa29-5a3c-496e-b3ba-f1de9203dfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h8/dz6krpcx2yb_86vz5sx_qczw0000gp/T/ipykernel_88029/3381465890.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  slimmed_frame['key'] = 1\n",
      "/var/folders/h8/dz6krpcx2yb_86vz5sx_qczw0000gp/T/ipykernel_88029/3381465890.py:57: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  cross_joined[col] = pd.to_datetime(cross_joined[col], errors='coerce')\n",
      "/var/folders/h8/dz6krpcx2yb_86vz5sx_qczw0000gp/T/ipykernel_88029/3381465890.py:57: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  cross_joined[col] = pd.to_datetime(cross_joined[col], errors='coerce')\n",
      "/var/folders/h8/dz6krpcx2yb_86vz5sx_qczw0000gp/T/ipykernel_88029/3381465890.py:57: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  cross_joined[col] = pd.to_datetime(cross_joined[col], errors='coerce')\n",
      "/var/folders/h8/dz6krpcx2yb_86vz5sx_qczw0000gp/T/ipykernel_88029/3381465890.py:57: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  cross_joined[col] = pd.to_datetime(cross_joined[col], errors='coerce')\n",
      "/var/folders/h8/dz6krpcx2yb_86vz5sx_qczw0000gp/T/ipykernel_88029/3381465890.py:57: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  cross_joined[col] = pd.to_datetime(cross_joined[col], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "parsed_100_frame = pd.read_csv('./web_data/parsed_I_data.csv', low_memory=False)\n",
    "\n",
    "# Filter for year 2024\n",
    "race_frame_2024 = parsed_100_frame[parsed_100_frame['year'] == 2024].copy()\n",
    "\n",
    "# Convert start time to datetime and decimal hours\n",
    "race_frame_2024['start_tod'] = pd.to_datetime(\n",
    "    race_frame_2024['start_tod'], format='%Y-%m-%d %H:%M:%S', errors='coerce'\n",
    ")\n",
    "\n",
    "def time_to_decimal_hours(t):\n",
    "    return t.hour + t.minute / 60 + t.second / 3600 if pd.notnull(t) else np.nan\n",
    "\n",
    "race_frame_2024['start_tod_decimal'] = round(\n",
    "    race_frame_2024['start_tod'].apply(time_to_decimal_hours), 2\n",
    ")\n",
    "\n",
    "# Select necessary columns, including rest stop times\n",
    "slimmed_frame = race_frame_2024[[\n",
    "    'rider_no', \n",
    "    'is_early_starter',\n",
    "    'is_late_starter',\n",
    "    'mph_25', 'mph_53', 'mph_73', 'mph_finish',\n",
    "    'start_tod', 'start_tod_decimal',\n",
    "    'ride_time_25_decimal', 'ride_time_53_decimal',\n",
    "    'ride_time_73_decimal', 'ride_time_finish_decimal',\n",
    "    'tod_25', 'tod_26', 'tod_53', 'tod_54', 'tod_73', 'tod_74'\n",
    "]]\n",
    "\n",
    "# Create the hour range series\n",
    "hour_range = np.linspace(6, 18, 49)  # Every 0.25 hour from 6 to 18\n",
    "hour_df = pd.DataFrame({'hour': hour_range})\n",
    "\n",
    "# Cross join\n",
    "slimmed_frame['key'] = 1\n",
    "hour_df['key'] = 1\n",
    "cross_joined = pd.merge(slimmed_frame, hour_df, on='key').drop('key', axis=1)\n",
    "\n",
    "# Ensure all relevant columns are numeric\n",
    "cols_to_float = [\n",
    "    'mph_25', 'mph_53', 'mph_73', 'mph_finish',\n",
    "    'ride_time_25_decimal', 'ride_time_53_decimal',\n",
    "    'ride_time_73_decimal', 'ride_time_finish_decimal',\n",
    "    'start_tod_decimal', 'hour'\n",
    "]\n",
    "\n",
    "cross_joined[cols_to_float] = cross_joined[cols_to_float].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Convert tod_* fields to decimal hours (needed for rest stop comparison)\n",
    "tod_columns = ['tod_25', 'tod_26', 'tod_53', 'tod_54', 'tod_73', 'tod_74']\n",
    "for col in tod_columns:\n",
    "    if not np.issubdtype(cross_joined[col].dtype, np.number):\n",
    "        cross_joined[col] = pd.to_datetime(cross_joined[col], errors='coerce')\n",
    "        cross_joined[col] = cross_joined[col].apply(time_to_decimal_hours)\n",
    "\n",
    "# Define race segments\n",
    "segments = [\n",
    "    {'mph_col': 'mph_25', 'end_time_col': 'ride_time_25_decimal'},\n",
    "    {'mph_col': 'mph_53', 'end_time_col': 'ride_time_53_decimal'},\n",
    "    {'mph_col': 'mph_73', 'end_time_col': 'ride_time_73_decimal'},\n",
    "    {'mph_col': 'mph_finish', 'end_time_col': 'ride_time_finish_decimal'},\n",
    "]\n",
    "\n",
    "# Define rest stop windows\n",
    "rest_stops = [\n",
    "    {'start': 'tod_25', 'end': 'tod_26', 'label': 'Stop 25'},\n",
    "    {'start': 'tod_53', 'end': 'tod_54', 'label': 'Stop 53'},\n",
    "    {'start': 'tod_73', 'end': 'tod_74', 'label': 'Stop 73'},\n",
    "]\n",
    "\n",
    "# Distance + status calculation\n",
    "def estimate_distance_and_status(row, segments, rest_stops):\n",
    "    elapsed_time = row['hour'] - row['start_tod_decimal']\n",
    "    distance = 0\n",
    "    prev_time = 0\n",
    "\n",
    "    for stop in rest_stops:\n",
    "        if pd.notnull(row[stop['start']]) and pd.notnull(row[stop['end']]):\n",
    "            if row[stop['start']] <= row['hour'] < row[stop['end']]:\n",
    "                return 0, stop['label']\n",
    "\n",
    "    for segment in segments:\n",
    "        seg_end_time = row[segment['end_time_col']]\n",
    "        if elapsed_time <= prev_time:\n",
    "            break\n",
    "        segment_time = min(elapsed_time, seg_end_time) - prev_time\n",
    "        distance += segment_time * row[segment['mph_col']]\n",
    "        prev_time = seg_end_time\n",
    "\n",
    "    return distance, \"Riding\"\n",
    "\n",
    "# Apply to each row\n",
    "cross_joined[['estimated_distance', 'status']] = cross_joined.apply(\n",
    "    lambda row: pd.Series(estimate_distance_and_status(row, segments, rest_stops)),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "def custom_distance_bucket(row):\n",
    "    if pd.isna(row['start_tod_decimal']) or pd.isna(row['hour']):\n",
    "        return np.nan\n",
    "\n",
    "    if row['hour'] < row['start_tod_decimal']:\n",
    "        return \"Not Started\"\n",
    "\n",
    "    elapsed_time = row['hour'] - row['start_tod_decimal']\n",
    "    \n",
    "    if pd.notnull(row['ride_time_finish_decimal']) and elapsed_time > row['ride_time_finish_decimal']:\n",
    "        return \"Finished\"\n",
    "\n",
    "    if isinstance(row['status'], str) and row['status'].startswith(\"Stop\"):\n",
    "        return row['status']\n",
    "\n",
    "    if pd.notnull(row['estimated_distance']):\n",
    "        return int(np.floor(row['estimated_distance'] / 5) * 5)\n",
    "\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "cross_joined['estimated_distance_bucket'] = cross_joined.apply(custom_distance_bucket, axis=1)\n",
    "\n",
    "# Drop rows with missing buckets\n",
    "grouped = cross_joined[cross_joined['estimated_distance_bucket'].notna()]\n",
    "\n",
    "# Group by hour and bucket\n",
    "rider_distribution = (\n",
    "    grouped.groupby(['hour', 'estimated_distance_bucket'], dropna=False)\n",
    "      .agg(\n",
    "          regular_riders=('rider_no', lambda x: x[(grouped.loc[x.index, 'is_early_starter'] == False) & (grouped.loc[x.index, 'is_late_starter'] == False)].nunique()),\n",
    "          early_starters=('rider_no', lambda x: x[grouped.loc[x.index, 'is_early_starter'] == True].nunique()),\n",
    "          late_starters=('rider_no', lambda x: x[grouped.loc[x.index, 'is_late_starter'] == True].nunique())\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Save to CSV\n",
    "rider_distribution.to_csv('./race_sim_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549addc5-f184-4676-aa66-5765f3194ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
